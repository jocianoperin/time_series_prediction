# ============================================================
#  MAIN ‚Äì PIPELINE DE PREVIS√ÉO DI√ÅRIA 2024 (PARALELO CONTROLADO)
#  ------------------------------------------------------------
#  Objetivo:
#    ‚Ä¢ Rodar XGBoost de forma concorrente (GPU leve)
#    ‚Ä¢ Rodar Rede Neural (LSTM) com exclusividade da GPU
#    ‚Ä¢ Consolidar previs√µes e m√©tricas por produto
# ============================================================

# ----- AJUSTES DE GPU (OTIMIZA√á√ÉO DE USO DE VRAM) ----------
import signal
import os
os.environ["OMP_NUM_THREADS"] = "2"
os.environ["OPENBLAS_NUM_THREADS"] = "2"
# os.environ["TF_GPU_ALLOCATOR"] = "cuda_malloc_async"

# ----- MULTIPROCESSAMENTO COM CONTEXTO LIMPO (CUDA) --------
import multiprocessing as mp
import traceback
import pandas as pd
# mp.set_start_method("spawn", force=True)  # configurado no bloco __main__

# ----- IMPORTS DO PIPELINE ----------------------------------
from utils.logging_config import get_logger
from data_preparation     import carregar_dados
from feature_engineering  import create_features
from train_xgboost        import train_xgboost
from train_nn             import train_neural_network
from compare_models       import compare_and_save_results
from utils.metrics        import calculate_metrics
from utils.gpu_utils      import free_gpu_memory
import tensorflow as tf
import gc

logger = get_logger(__name__)

# ============================================================
#  PROCESSA UM √öNICO PRODUTO ‚Äì ETAPAS COMPLETAS
# ============================================================
def processar_produto(barcode: str, df_raw, xgb_gpu_lock, nn_gpu_lock, proc_lock):
    """
    Executa a cadeia completa de predi√ß√£o para um produto:
    feature engineering ‚Üí XGBoost ‚Üí LSTM ‚Üí consolida√ß√£o de m√©tricas.
    """
    
    # ‚Äî‚Äî‚Äî‚Äî‚Äî Normaliza `barcode` removendo prefixo "produto_" e extens√£o ".csv"
    base = os.path.splitext(barcode)[0]
    if base.startswith("produto_"):
        barcode = base[len("produto_"):]
    else:
        barcode = base

    try:
        logger.info(f"[{barcode}] Iniciando processamento‚Ä¶")

        # ----- FEATURE ENGINEERING --------------------------
        df = create_features(df_raw)
        results = {}

        # ----- XGBOOST (GPU leve, concorrente) --------------
        with xgb_gpu_lock:
            logger.info(f"[{barcode}] Iniciando XGBoost‚Ä¶")
            df_xgb_all, xgb_metrics, df_xgb_2024 = train_xgboost(df, barcode)
            results["xgboost"] = {"metrics": xgb_metrics,
                                  "predictions": df_xgb_2024}
            
            logger.info(f"[{barcode}] XGBoost conclu√≠do")
            free_gpu_memory()

        # ----- LSTM / NN (GPU pesada, uso exclusivo) ---------
        """
        with nn_gpu_lock:
            logger.info(f"[{barcode}] Iniciando LSTM (NN)‚Ä¶")
            df_nn_all, nn_metrics, df_nn_2024 = train_neural_network(df, barcode)
            results["nn"] = {"metrics": nn_metrics,
                             "predictions": df_nn_2024}
            
            logger.info(f"[{barcode}] LSTM conclu√≠do")
        
        # ----- CONSOLIDA√á√ÉO FINAL ----------------------------
        compare_and_save_results(barcode, results)
        """

    except Exception as exc:
        logger.error(f"[{barcode}] Erro no pipeline: {exc}")
        logger.error(traceback.format_exc())
    finally:
        # Limpa completamente a sess√£o para liberar VRAM
        free_gpu_memory() 
        tf.keras.backend.clear_session()
        gc.collect()
        free_gpu_memory()
        proc_lock.release()

# ============================================================
#  EXECU√á√ÉO PRINCIPAL ‚Äì PARALELO CONTROLADO
# ============================================================
def main(proc_lock, xgb_gpu_lock, nn_gpu_lock):
    logger.info("üöÄ Iniciando pipeline de predi√ß√£o di√°ria 2024")

    # ----- EXECU√á√ÉO EM MULTIPROCESSAMENTO -------------------
    batch_size = 20                      # processa em batches de 20 CSVs por vez

    # ------------------------------------------------------------
    #  CARREGA .CSV E MOVE PARA processed AP√ìS PROCESSAMENTO OK
    # ------------------------------------------------------------
    raw_dir = "data/raw"
    processed_dir = os.path.join(raw_dir, "processed")
    os.makedirs(processed_dir, exist_ok=True)

    arquivos = [f for f in os.listdir(raw_dir) if f.endswith(".csv")]
    total = len(arquivos)
    logger.info(f"Arquivos encontrados: {total} CSV(s) em '{raw_dir}'.")

    # ------------------------------------------------------------
    #  LOOP DE BATCHES (20 EM 20)
    # ------------------------------------------------------------
    for batch_idx in range(0, total, batch_size):
        batch_files = arquivos[batch_idx : batch_idx + batch_size]
        n_batch = len(batch_files)

        logger.info(
            f"üîÑ Iniciando batch {batch_idx//batch_size + 1}: "
            f"{n_batch} arquivos CSV "
            f"(√≠ndices {batch_idx}‚Äì{batch_idx + n_batch - 1})"
        )

        processes = []  # [(Process, filepath, filename)]

        # ----- LAN√áA TODOS OS PROCESSOS DO BATCH -------------
        for filename in batch_files:
            base = os.path.splitext(filename)[0]
            barcode = base[len("produto_"):] if base.startswith("produto_") else base

            filepath = os.path.join(raw_dir, filename)
            df = pd.read_csv(filepath, parse_dates=["Date"])

            proc_lock.acquire()  # respeita MAX_PARALLEL_PROCS
            p = mp.Process(
                target=processar_produto,
                args=(filename, df, xgb_gpu_lock, nn_gpu_lock, proc_lock),
                name=f"proc_{barcode}",
            )
            p.start()

            processes.append((p, filepath, filename))
            logger.info(f"{len(mp.active_children())} processos ativos‚Ä¶")

        # ----- ESPERA TODOS OS PROCESSOS TERMINAREM -----------
        for proc, path, fname in processes:
            proc.join()                        # bloqueia at√© finalizar
            ec = proc.exitcode                 # exitcode confi√°vel

            # ----- AVALIA EXITCODE & MOVE ARQUIVO --------------
            if ec == 0:
                dest = os.path.join(processed_dir, fname)
                try:
                    os.rename(path, dest)
                    logger.info(f"‚úÖ '{fname}' movido para '{processed_dir}'")
                except OSError as e:
                    logger.error(f"‚ö†Ô∏è  N√£o foi poss√≠vel mover '{fname}': {e}")
            elif ec == -signal.SIGKILL:
                logger.error(f"‚ùå '{fname}' foi morto por SIGKILL (poss√≠vel OOM)")
            elif ec is not None and ec < 0:
                logger.error(f"‚ùå '{fname}' morto pelo sinal {-ec}")
            else:
                logger.error(f"‚ùå Falha ao processar '{fname}' (exitcode={ec})")

        logger.info(f"‚úÖ Batch {batch_idx//batch_size + 1} conclu√≠do")

    logger.info("‚úÖ Pipeline conclu√≠do para todos os produtos")

# ============================================================
#  PONTO DE ENTRADA
# ============================================================
if __name__ == "__main__":
    # ----- MULTIPROCESSAMENTO COM CONTEXTO LIMPO (CUDA) -----
    mp.set_start_method("spawn", force=True)

    # ----- LIMITES DE CONCORR√äNCIA ---------------------------
    MAX_PARALLEL_PROCS   = 8  # M√°x. de processos simult√¢neos
    MAX_XGB_CONCURRENT   = 8  # M√°x. de XGBoosts simult√¢neos na GPU
    proc_lock    = mp.Semaphore(MAX_PARALLEL_PROCS)   # controle global
    xgb_gpu_lock = mp.Semaphore(MAX_XGB_CONCURRENT)   # GPU leve
    nn_gpu_lock  = mp.Semaphore(1)                    # GPU exclusiva para NN

    # ----- INICIA O PIPELINE --------------------------------
    main(proc_lock, xgb_gpu_lock, nn_gpu_lock)
