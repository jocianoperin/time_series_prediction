# ============================================================
#  MAIN ‚Äì PIPELINE DE PREVIS√ÉO DI√ÅRIA 2024 (PARALELO CONTROLADO)
#  ------------------------------------------------------------
#  Objetivo:
#    ‚Ä¢ Rodar XGBoost de forma concorrente (GPU leve)
#    ‚Ä¢ Rodar Rede Neural (LSTM) com exclusividade da GPU
#    ‚Ä¢ Consolidar previs√µes e m√©tricas por produto
# ============================================================

# ----- AJUSTES DE GPU (OTIMIZA√á√ÉO DE USO DE VRAM) ----------
import signal
import os
os.environ["OMP_NUM_THREADS"] = "2"
os.environ["OPENBLAS_NUM_THREADS"] = "2"
# os.environ["TF_GPU_ALLOCATOR"] = "cuda_malloc_async"

# ----- MULTIPROCESSAMENTO COM CONTEXTO LIMPO (CUDA) --------
import multiprocessing as mp
import traceback
import pandas as pd
#mp.set_start_method("spawn", force=True)

# ----- LIMITES DE CONCORR√äNCIA -----------------------------
#MAX_PARALLEL_PROCS = 4     # M√°ximo de processos simult√¢neos
#MAX_XGB_CONCURRENT = 2     # XGBoosts simult√¢neos na GPU
#proc_lock    = mp.Semaphore(MAX_PARALLEL_PROCS)   # controle global
#xgb_gpu_lock = mp.Semaphore(MAX_XGB_CONCURRENT)   # GPU leve
#nn_gpu_lock  = mp.Semaphore(1)                    # GPU exclusiva para NN

# ----- IMPORTS DO PIPELINE ----------------------------------
from utils.logging_config import get_logger
from data_preparation     import carregar_dados
from feature_engineering  import create_features
from train_xgboost        import train_xgboost
from train_nn             import train_neural_network
from compare_models       import compare_and_save_results
from utils.metrics        import calculate_metrics
from utils.gpu_utils      import free_gpu_memory
import tensorflow as tf
import gc

logger = get_logger(__name__)

# ============================================================
#  PROCESSA UM √öNICO PRODUTO ‚Äì ETAPAS COMPLETAS
# ============================================================
def processar_produto(barcode: str, df_raw, xgb_gpu_lock, nn_gpu_lock, proc_lock):
    """
    Executa a cadeia completa de predi√ß√£o para um produto:
    feature engineering ‚Üí XGBoost ‚Üí LSTM ‚Üí consolida√ß√£o de m√©tricas.
    """
    
    # ‚Äî‚Äî‚Äî‚Äî‚Äî Normaliza `barcode` removendo prefixo "produto_" e extens√£o ".csv"
    base = os.path.splitext(barcode)[0]
    if base.startswith("produto_"):
        barcode = base[len("produto_"):]
    else:
        barcode = base

    slot_released = False
    
    try:
        logger.info(f"[{barcode}] Iniciando processamento‚Ä¶")

        # ----- FEATURE ENGINEERING --------------------------
        df = create_features(df_raw)
        results = {}

        # ----- XGBOOST (GPU leve, concorrente) --------------
        with xgb_gpu_lock:
            logger.info("Iniciando XGBoost‚Ä¶")
            df_xgb_all, xgb_metrics, df_xgb_2024 = train_xgboost(df, barcode)
            results["xgboost"] = {"metrics": xgb_metrics,
                                  "predictions": df_xgb_2024}
            
            logger.info(f"[{barcode}] XGBoost conclu√≠do")
            free_gpu_memory()

            # Comentando para liberar apenas ao final de tudo, evitando sobrecarga da RAM
            # slot_released = True
            # proc_lock.release()
            # logger.debug(f"[{barcode}] Slot global liberado ap√≥s XGBoost")

        # ----- LSTM / NN (GPU pesada, uso exclusivo) ---------
        """with nn_gpu_lock:
            logger.info("Iniciando LSTM (NN)‚Ä¶")
            df_nn_all, nn_metrics, df_nn_2024 = train_neural_network(df, barcode)
            results["nn"] = {"metrics": nn_metrics,
                             "predictions": df_nn_2024}
            
            logger.info(f"[{barcode}] LSTM conclu√≠do")
        
        # ----- CONSOLIDA√á√ÉO FINAL ----------------------------
        compare_and_save_results(barcode, results)"""

    except Exception as exc:
        logger.error(f"[{barcode}] Erro no pipeline: {exc}")
        logger.error(traceback.format_exc())
    finally:
        free_gpu_memory() 
        # limpa sess√£o TF/Keras para realmente liberar a VRAM
        tf.keras.backend.clear_session()
        gc.collect()
        free_gpu_memory()
        proc_lock.release()

# ============================================================
#  EXECU√á√ÉO PRINCIPAL ‚Äì PARALELO CONTROLADO
# ============================================================
def main(proc_lock, xgb_gpu_lock, nn_gpu_lock):
    logger.info("üöÄ Iniciando pipeline de predi√ß√£o di√°ria 2024")

    # ----- EXECU√á√ÉO EM MULTIPROCESSAMENTO -------------------
    # Processa em batches de 20 CSVs por vez
    batch_size = 20

    # ------------------------------------------------------------
    #  CARREGA .CSV E MOVE PARA processed AP√ìS PROCESSAMENTO OK
    # ------------------------------------------------------------
    raw_dir = "data/raw"
    processed_dir = os.path.join(raw_dir, "processed")
    os.makedirs(processed_dir, exist_ok=True)

    # Lista todos os CSVs ainda n√£o processados
    arquivos = [f for f in os.listdir(raw_dir) if f.endswith(".csv")]
    total = len(arquivos)
    logger.info(f"Arquivos encontrados: {total} CSV(s) em '{raw_dir}'.")

    for batch_idx in range(0, total, batch_size):
        batch_files = arquivos[batch_idx:batch_idx + batch_size]
        n_batch = len(batch_files)
        logger.info(f"üîÑ Iniciando batch {batch_idx//batch_size + 1}: "
                    f"{n_batch} arquivos CSV (√≠ndices {batch_idx}‚Äì{batch_idx + n_batch - 1})")
        processes = []

        for filename in batch_files:
            # ‚Äî‚Äî‚Äî Extrai o barcode: remove 'produto_' e '.csv'
            base = os.path.splitext(filename)[0]
            if base.startswith("produto_"):
                barcode = base[len("produto_"):]
            else:
                barcode = base

            filepath = os.path.join(raw_dir, filename)
            # L√™ o CSV j√° convertendo a coluna Date para datetime
            df = pd.read_csv(filepath, parse_dates=["Date"])

            proc_lock.acquire()   # respeita MAX_PARALLEL_PROCS
            p = mp.Process(
                target=processar_produto,
                args=(filename, df, xgb_gpu_lock, nn_gpu_lock, proc_lock)
            )
            p.start()
            processes.append((p, filepath))
            logger.info(f"{len(mp.active_children())} processos ativos‚Ä¶")

        ec = p.exitcode

        if ec == 0:
            # sucesso
            dest = os.path.join(processed_dir, filename)
            os.rename(filepath, dest)
            logger.info(f"‚úÖ '{filename}' movido para '{processed_dir}'")
        elif ec == -signal.SIGKILL:
            # morto por SIGKILL (OOM-killer)
            logger.error(f"‚ùå '{filename}' foi morto por SIGKILL (poss√≠vel OOM)")
        elif ec < 0:
            # outro sinal
            sig = -ec
            logger.error(f"‚ùå '{filename}' morto pelo sinal {sig}")
        else:
            # exitcode > 0 (exce√ß√£o Python)
            logger.error(f"‚ùå Falha ao processar '{filename}' (exitcode={ec})")

        logger.info(f"‚úÖ Batch {batch_idx//batch_size + 1} conclu√≠do")
    
    # ----- VERS√ÉO SEQUENCIAL (desativada) -------------------
    # for barcode, df in dados.items():
    #     processar_produto(barcode, df, xgb_gpu_lock, nn_gpu_lock, proc_lock)

    logger.info("‚úÖ Pipeline conclu√≠do para todos os produtos")

if __name__ == "__main__":
    # ----- MULTIPROCESSAMENTO COM CONTEXTO LIMPO (CUDA) --------
    mp.set_start_method("spawn", force=True)

    # ----- LIMITES DE CONCORR√äNCIA -----------------------------
    MAX_PARALLEL_PROCS = 8     # M√°ximo de processos simult√¢neos
    MAX_XGB_CONCURRENT = 8     # XGBoosts simult√¢neos na GPU
    proc_lock    = mp.Semaphore(MAX_PARALLEL_PROCS)   # controle global
    xgb_gpu_lock = mp.Semaphore(MAX_XGB_CONCURRENT)   # GPU leve
    nn_gpu_lock  = mp.Semaphore(1)                    # GPU exclusiva para NN

    # Inicia o pipeline passando os sem√°foros criados no escopo do pai
    main(proc_lock, xgb_gpu_lock, nn_gpu_lock)